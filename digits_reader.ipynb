{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = tf.keras.datasets.mnist\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset manually \n",
    "- Download the data manually from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
    "- Create a folder in a location that you have saved your jupyter notebook and call it dataset\n",
    "- Move the downloaded file from 'Downloads' to 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_test', 'x_train', 'y_train', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset manually \n",
    "mnist = np.load('dataset/mnist.npz')\n",
    "print(mnist.files)\n",
    "\n",
    "x_train = mnist['x_train']\n",
    "y_train = mnist['y_train']\n",
    "x_test = mnist['x_test'] \n",
    "y_test = mnist['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize what is in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_size = 28\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(x_train[100].reshape(img_size, img_size), cmap = plt.cm.binary)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(x_train[900].reshape(img_size, img_size), cmap = plt.cm.binary)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(x_train[670].reshape(img_size, img_size), cmap = plt.cm.binary)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(x_train[1999].reshape(img_size, img_size), cmap = plt.cm.binary)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data (scale it between 0 and 1)\n",
    "Let's first take a look at one sample in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the printed array, currently our pixels (features) are between 0 and 255. When we normalize our data, pixels will be between 0 and 1. Therefore, our network will learn easier! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how our data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00393124, 0.02332955, 0.02620568,\n",
       "        0.02625207, 0.17420356, 0.17566281, 0.28629534, 0.05664824,\n",
       "        0.51877786, 0.71632322, 0.77892406, 0.89301644, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05780486, 0.06524513,\n",
       "        0.16128198, 0.22713296, 0.22277047, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.32678448, 0.368094  , 0.3747499 ,\n",
       "        0.79066747, 0.67980478, 0.61494005, 0.45002403, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12250613, 0.45858525, 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.32420121, 0.15214552, 0.17865984,\n",
       "        0.25626376, 0.1573102 , 0.12298801, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04500225, 0.4219755 , 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.32790981, 0.28826244,\n",
       "        0.26543758, 0.34149427, 0.31128482, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1541463 , 0.28272888,\n",
       "        0.18358693, 0.37314701, 0.33153488, 0.26569767, 0.01601458,\n",
       "        0.        , 0.05945042, 0.19891229, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0253731 ,\n",
       "        0.00171577, 0.22713296, 0.33153488, 0.11664776, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20500962, 0.33153488, 0.24625638, 0.00291174,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01622378, 0.24897876, 0.32790981, 0.10191096,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04586451, 0.31235677, 0.32757096,\n",
       "        0.23335172, 0.14931733, 0.00129164, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10498298, 0.34940902,\n",
       "        0.3689874 , 0.34978968, 0.15370495, 0.04089933, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06551419,\n",
       "        0.27127137, 0.34978968, 0.32678448, 0.245396  , 0.05882702,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02333517, 0.12857881, 0.32549285, 0.41390126, 0.40743158,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32161793, 0.41390126, 0.54251585,\n",
       "        0.20001074, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06697006,\n",
       "        0.18959827, 0.25300993, 0.32678448, 0.41390126, 0.45100715,\n",
       "        0.00625034, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.05110617, 0.19182076, 0.33339444,\n",
       "        0.3689874 , 0.34978968, 0.32678448, 0.40899334, 0.39653769,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04117838, 0.16813739, 0.28960162, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.25961929, 0.12760592, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.04431706, 0.11961607,\n",
       "        0.36545809, 0.37314701, 0.33153488, 0.32790981, 0.36833534,\n",
       "        0.28877275, 0.111988  , 0.00258328, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05298497, 0.42752138, 0.4219755 , 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.25273681, 0.11646967,\n",
       "        0.01312603, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.37491383,\n",
       "        0.56222061, 0.66525569, 0.63253163, 0.48748768, 0.45852825,\n",
       "        0.43408872, 0.359873  , 0.17428513, 0.01425695, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.92705966,\n",
       "        0.82698729, 0.74473314, 0.63253163, 0.4084877 , 0.24466922,\n",
       "        0.22648107, 0.02359823, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a look at our data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_size = 28\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(x_train[100].reshape(img_size, img_size), cmap = plt.cm.binary)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(x_train[900].reshape(img_size, img_size), cmap = plt.cm.binary)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(x_train[670].reshape(img_size, img_size), cmap = plt.cm.binary)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(x_train[1999].reshape(img_size, img_size), cmap = plt.cm.binary)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration\n",
    "In this workshop, we will use the 'mnist dataset' to classify the hand written digits images. In this dataset, there are 70000 images. As digits are from 0 to 9, therefore there are 10 unique digits in this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28)\n",
      "y_train shape:  (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape: \" , x_train.shape)\n",
    "print(\"y_train shape: \" , y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The shape of the x_train is (60000, 28, 28) <br>\n",
    "> 60000 means that we have 60000 images<br>\n",
    "> 28 means that our image size is 28x28 (28x28 pixels)<br>\n",
    "- The shape of the Y is (60000,)<br>\n",
    "> 60000 means that we have 60000 labels (10 unique lables from 0 to 9) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's build our feed forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a basic feed-forward model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer: Our input array (X) is a 3 dimensional array. \n",
    "#In order to be able to use it in our first deep learning model, \n",
    "#we need to make it flatten (2D).So, we need to take this 28x28 image, and make it a flat 1x784\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "\n",
    "# a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "\n",
    "# our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2618 - acc: 0.9247\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1079 - acc: 0.9667\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0738 - acc: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb35a87e10>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model \n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 20us/step\n",
      "0.09363970999494195\n",
      "0.9706\n"
     ]
    }
   ],
   "source": [
    "# Test if the model generalize or overfit\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('digit.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_model = tf.keras.models.load_model('digit.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = digit_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.6583052e-11 3.3914485e-08 1.9461515e-07 ... 9.9998963e-01\n",
      "  1.1656626e-10 1.2059029e-07]\n",
      " [7.4752835e-09 1.4052712e-04 9.9983454e-01 ... 6.6175993e-08\n",
      "  1.2733738e-06 1.9405559e-10]\n",
      " [2.7666033e-07 9.9968529e-01 1.3809693e-05 ... 2.0912406e-04\n",
      "  5.1620995e-05 3.6066538e-06]\n",
      " ...\n",
      " [4.4608115e-08 5.0809281e-06 2.7248429e-08 ... 2.5988054e-05\n",
      "  5.0891285e-06 3.5097080e-03]\n",
      " [1.6911763e-07 9.7068903e-07 2.8163861e-08 ... 7.9183901e-06\n",
      "  2.1436064e-05 3.8204092e-08]\n",
      " [2.6660525e-06 1.2293344e-08 2.3061411e-06 ... 1.0165040e-08\n",
      "  1.6208338e-07 4.7041596e-08]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predictions[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIQAAACECAYAAABRRIOnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAABKBJREFUeJzt3UsobW0cx/HtkqJcUpSBSyKFpEiUkTKRUmKmZMJAlLmhmEtmMjJDhpQoJbkUIVLKROSS3HLL5R29T8/vyTp03m3Ze73fz+j/nP85Z61zzu88z1p7rb1WzMfHRwj4V+xv7wAiC4GAIBAQBAKCQEAQCAgCAUEgIOJ93h6fgkWOmM9+kBkCgkBAEAgIAgFBICAIBASBgCAQEAQCgkBAEAgIAgFBICD8vtoZsba2tkxdVlYmvcPDQ1PPz89Lzx3X1dV5bqO6utrUlZWVf7WfP40ZAoJAQBAIiBifv8r3q3dMPT4+mnpoaEh6CwsLpr69vZXe3d2dqZ+enqQXE6M3Hr2/v3tuPzMz09Q5OTnS6+/vN7V9rPGDuGMKXyMQEP+r086JiQlTr66uSu/5+dnU19fX0rOnd3vaD4VCoZSUFBnbS4a7fKyvr5v65uZGeqOjo6bOzc2VXlZWVsgvzBAQBAKCQEAE+hji5ORExisrK54/NyMjw9TDw8PSy8vLM3Vqaqr0kpKSPH9P95R+ZGTE1JOTk9KzT4lnZ2el19LSYurk5GTP7YUDMwQEgYAI9JLhfqp4f39vavcTxo6ODlPX1NSEZfvuNnp6ekydkJAgvcXFRVPv7OxIr7Cw0NS1tbVh2TcvzBAQBAKCQEAE+hji9fXVs1dfXy/j1tbWn94d0dXVJWP3uMFmX4nlGAK+IhAQgV4yZmZmPHtFRUU+7snXysvLTb23tye9Py0n4cYMAUEgIAgEROCOIc7Pz03t3vlkX5nMz8/3bZ++o7S01NTuMYSfmCEgCARE4JaMpaUlU19cXEjP/s5mcXGxb/sUTZghIAgEBIGACNwxxPLysqkTExOl19DQ4PfuRB1mCAgCARG4JcPmficy0q5wRiJmCAgCAUEgIKL+GOL4+FjGb29vv7QnwcAMAUEgIAgERNQfQ2RnZ8vY/sKNn89m+q82NjY8e/Hx/v0zMUNAEAiIqF8yotXBwYGM7SUjPT1det3d3b7sUyjEDAEHgYAgEBAcQ/hod3fX1NPT09J7eHgwdUVFhfTC9cyr72CGgCAQEFG/ZDQ3N8vYvbH2N7lPwx8bGzO1+8lkSUmJqZuamqQXFxf3A3v3OWYICAIBQSAgov4YYmpqSsZ9fX2mtp8wHwrpy9TC9VT5/f19GY+Pj5t6e3tbekdHR6Z238zT29travcFbX5ihoAgEBBRv2T8yenpqYwHBwdN7d50Yi8n7qOIXl5eTO2eAm5ubsr48vLSc3/sF7E0NjZKr6CgwPPX+YkZAoJAQBAIiMC9+3ttbc3Uc3Nz0rOvNrrHCVdXV6Y+OzuTnv2S19hY/T/kvjXH/vtMS0uTnn1K3NnZ+fkfwD+8+xtfIxAQgTvtrKqqMrX7PIiBgQFTu0vG32pra5OxfdWyvb09LNvwEzMEBIGAIBAQgTvtxLdx2omvEQgIAgFBICAIBASBgCAQEAQCgkBAEAgIAgFBICAIBITfd0x9eoUNkYMZAoJAQBAICAIBQSAgCAQEgYAgEBAEAoJAQBAICAIBQSAgCAQEgYAgEBAEAoJAQBAICAIBQSAgCAQEgYD4Bx3d/5AehTtaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_size = 28\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(x_test[10].reshape(img_size, img_size), cmap = plt.cm.binary)\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
